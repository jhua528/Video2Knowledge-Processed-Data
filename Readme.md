# ğŸ“¦ Video2Knowledge â€” Experimental Results and Data
*Laboratory for Industry 4.0 Smart Manufacturing Systems (LISMS)*


This repository contains the **experimental results and supplementary data** referenced in the paper:

> **Video2Knowledge: Extracting Task Knowledge from Monocular RGB Videos for Generalizable Robot Behavior**

---

## ğŸ“‚ Contents

This repository provides **processed results** derived from the experiments described in the paper, including:

- ğŸ¥ **Videos**  
  Demonstration and qualitative result visualizations.

- ğŸ–¼ï¸ **Images**  
  Pose renderings, and visualization outputs.

- ğŸ“ **Text Files**  
  Extracted structured task knowledge and evaluation summaries.

- ğŸ“„ **JSON Files**  
  Structured representations of motion_analysis, event nodes, and action sequences.

These data are intended to support **result verification, qualitative analysis** of the reported findings.

---

## ğŸ“¬ Access to Full Data

If you require **complete data**, including intermediate results (e.g., object poses, hand poses, and detailed processing logs) for **review/researach purposes**, please contact the authors directly.

ğŸ“§ **Contact:**  
*The authorâ€™s email address*

jan.polzer@auckland.ac.nz
or
jinyi.huang@auckland.ac.nz

---

## ğŸ“„ License

This repository is provided for **academic and research use only**. Please refer to the paper for details.
